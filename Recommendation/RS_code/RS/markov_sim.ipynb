{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markov similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "sc = SparkContext(\"spark://39.99.129.214:7077\", \"SecondApp\")\n",
    "spark = SparkSession.builder.master(\"spark://39.99.129.214:7077\").config(conf=SparkConf()).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "'''\n",
    "specify collection name, here:\n",
    "    ratings_temp: original ml-20m ratings\n",
    "    ratings_sort: sort ratings_temp by userId (ascend) and timestamp (ascend)\n",
    "'''\n",
    "def read_mongo(collection):\n",
    "    client = pymongo.MongoClient(\"39.98.136.173\", 9099)\n",
    "    client.movie.authenticate('user','cloud',mechanism='SCRAM-SHA-1')\n",
    "    database = client['movie']\n",
    "    ratings = database['ratings_sort']\n",
    "    cursor = ratings.find()\n",
    "    cnt = 0\n",
    "    #df = pd.DataFrame(columns=('userId','movieId','rating','timestamp'))\n",
    "    df = [] \n",
    "    for i in tqdm(range(2000000)):\n",
    "        #userId = copy.deepcopy(cursor[i]['userId'])\n",
    "        movieId = cursor[i]['movieId']\n",
    "        #rating = copy.deepcopy(cursor[i]['rating'])\n",
    "        #timestamp = copy.deepcopy(cursor[i]['timestamp'])\n",
    "    #         print(userId,movieId,rating,timestamp)\n",
    "    #         new = pd.DataFrame({'userId':[userId],'movieId':[movieId],'rating':[rating],'timestamp':[timestamp]})\n",
    "    #         print(new)\n",
    "        #df.append(pd.DataFrame(record,index=[0]),ignore_index=True)\n",
    "        df.append([movieId])\n",
    "        cnt = cnt + 1\n",
    "        if cnt == 2000000:\n",
    "            break\n",
    "    \n",
    "#     df = pd.DataFrame(tqdm(list(cursor)))\n",
    "#     df = df[['userId', 'movieId', 'rating', 'timestamp']]\n",
    "#     spark = SparkSession.builder.appName('readMongo').getOrCreate()\n",
    "#     sqlContest = SQLContext(spark)\n",
    "#     print(\"creating spark dataframe......\")\n",
    "#     spark_df = sqlContest.createDataFrame(df)\n",
    "#     return spark_df\n",
    "df = read_mongo('ratings_sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('/usr/dataset/ml-20m/ratings.csv')\n",
    "df['userId'] = df['movieId'].shift(1)\n",
    "df = df.fillna(1)\n",
    "df['userId'] = np.array(df['userId'].values,dtype=np.int)\n",
    "df['rating'] = np.random.randint(0,2,len(df))\n",
    "df[['userId','movieId','rating']].to_csv('/usr/dataset/ml-20m/markov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('RS').getOrCreate()\n",
    "# load dataset\n",
    "df = spark.read.csv('/usr/dataset/ml-20m/markov.csv', inferSchema=True, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n",
      "|_c0|userId|movieId|rating|\n",
      "+---+------+-------+------+\n",
      "|  0|     1|      2|     0|\n",
      "|  1|     2|     29|     1|\n",
      "|  2|    29|     32|     1|\n",
      "|  3|    32|     47|     0|\n",
      "|  4|    47|     50|     0|\n",
      "|  5|    50|    112|     0|\n",
      "|  6|   112|    151|     1|\n",
      "|  7|   151|    223|     1|\n",
      "|  8|   223|    253|     1|\n",
      "|  9|   253|    260|     1|\n",
      "+---+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userCount_df = df.groupBy('userId').count().orderBy('count', ascending=False)\n",
    "# Spark's DataFrame --> Pandas's DataFrame\n",
    "user_df = userCount_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+-----------+\n",
      "|_c0|userId|movieId|rating|movieId_num|\n",
      "+---+------+-------+------+-----------+\n",
      "|  0|     1|      2|     0|      125.0|\n",
      "|  1|     2|     29|     1|      564.0|\n",
      "|  2|    29|     32|     1|       19.0|\n",
      "|  3|    32|     47|     0|       23.0|\n",
      "|  4|    47|     50|     0|       14.0|\n",
      "|  5|    50|    112|     0|      370.0|\n",
      "|  6|   112|    151|     1|      335.0|\n",
      "|  7|   151|    223|     1|      106.0|\n",
      "|  8|   223|    253|     1|       77.0|\n",
      "|  9|   253|    260|     1|        5.0|\n",
      "+---+------+-------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "stringIndexer = StringIndexer(inputCol='movieId', outputCol='movieId_num')\n",
    "model = stringIndexer.fit(df)\n",
    "new_df  = model.transform(df)\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df, (13996257, 5)\n",
      "test_df, (6004006, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = new_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "print('train_df, (%d, %d)'%(train_df.count(), len(train_df.columns)))\n",
    "print('test_df, (%d, %d)'%(test_df.count(), len(test_df.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "#train for model\n",
    "rec = ALS(maxIter=10, regParam=0.01, userCol='userId', itemCol='movieId_num', ratingCol='rating', nonnegative=True,\n",
    "                 coldStartStrategy='drop')\n",
    "rs_model = rec.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------+----------+\n",
      "|userId|movieId|movieId_num|prediction|\n",
      "+------+-------+-----------+----------+\n",
      "|  1591|     17|      148.0|  0.466884|\n",
      "|  1127|     17|      148.0|0.45668304|\n",
      "|  2563|     17|      148.0|0.46466967|\n",
      "|  4161|     17|      148.0|0.47137365|\n",
      "|  4929|     17|      148.0|0.51497185|\n",
      "| 48780|     17|      148.0|0.45662728|\n",
      "| 56941|     17|      148.0| 0.5391659|\n",
      "|  2996|     17|      148.0|0.46675533|\n",
      "|  6482|     17|      148.0|0.49000967|\n",
      "| 76293|     17|      148.0| 0.5333507|\n",
      "|  8665|     17|      148.0|0.46893552|\n",
      "|101142|     17|      148.0|0.44186097|\n",
      "|128830|     17|      148.0|0.26811567|\n",
      "|  5995|     17|      148.0| 0.4856425|\n",
      "|  6722|     17|      148.0| 0.5723945|\n",
      "|  6832|     17|      148.0|0.46817586|\n",
      "| 27822|     17|      148.0|0.46095657|\n",
      "|  1466|     17|      148.0| 0.4438986|\n",
      "|  4396|     17|      148.0|0.44765642|\n",
      "|120132|     17|      148.0|0.19979942|\n",
      "+------+-------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test for model\n",
    "test = test_df.select(['userId','movieId','movieId_num'])\n",
    "test_pred = rs_model.transform(test)\n",
    "test_pred.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse is 0.502530\n"
     ]
    }
   ],
   "source": [
    "#test rmse for model\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "test_pred = rs_model.transform(test_df)\n",
    "\n",
    "evaluate_result = RegressionEvaluator(metricName='rmse', predictionCol='prediction', labelCol='rating')\n",
    "rmse = evaluate_result.evaluate(test_pred)\n",
    "print('test rmse is %f'%rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|148    |66    |\n",
      "|463    |66    |\n",
      "|471    |66    |\n",
      "|496    |66    |\n",
      "|833    |66    |\n",
      "|1088   |66    |\n",
      "|1238   |66    |\n",
      "|1342   |66    |\n",
      "|1580   |66    |\n",
      "|1591   |66    |\n",
      "+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#e.g. recommend movie for user 66\n",
    "# total movies\n",
    "nunique_movies = new_df.select('movieId').distinct()\n",
    "a = nunique_movies.alias('a')\n",
    "user_id = 66\n",
    "# user_id = 66，看过的电影\n",
    "watched_movies = new_df.filter(new_df['userId'] == user_id).select('movieId').distinct()\n",
    "b = watched_movies.alias('b')\n",
    "# a join b\n",
    "total_movies = a.join(b, a.movieId == b.movieId, how='left')\n",
    "user_66_not_watched_movies = total_movies.where(col('b.movieId').isNull()).select(a.movieId).distinct()\n",
    "user_66_not_watched_movies = user_66_not_watched_movies.withColumn('userId', lit(int(user_id)))\n",
    "user_66_not_watched_movies.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommendation for all users\n",
    "rec = rs_model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec= rec.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rec = df_rec.sort_values(by='userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5355</th>\n",
       "      <td>1</td>\n",
       "      <td>[(14672, 1.1313905715942383), (17758, 1.082917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22045</th>\n",
       "      <td>2</td>\n",
       "      <td>[(18198, 1.1249234676361084), (18792, 1.076898...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>3</td>\n",
       "      <td>[(18804, 1.0842939615249634), (18198, 1.082339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12871</th>\n",
       "      <td>4</td>\n",
       "      <td>[(18198, 1.1037191152572632), (18804, 1.073117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>5</td>\n",
       "      <td>[(21832, 1.0734281539916992), (18804, 1.064790...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11862</th>\n",
       "      <td>131248</td>\n",
       "      <td>[(13951, 1.4968010187149048), (15278, 1.471555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>131256</td>\n",
       "      <td>[(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24171</th>\n",
       "      <td>131258</td>\n",
       "      <td>[(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>131260</td>\n",
       "      <td>[(18792, 2.265856981277466), (14672, 2.2063508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19746</th>\n",
       "      <td>131262</td>\n",
       "      <td>[(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25297 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId                                    recommendations\n",
       "5355        1  [(14672, 1.1313905715942383), (17758, 1.082917...\n",
       "22045       2  [(18198, 1.1249234676361084), (18792, 1.076898...\n",
       "6363        3  [(18804, 1.0842939615249634), (18198, 1.082339...\n",
       "12871       4  [(18198, 1.1037191152572632), (18804, 1.073117...\n",
       "8245        5  [(21832, 1.0734281539916992), (18804, 1.064790...\n",
       "...       ...                                                ...\n",
       "11862  131248  [(13951, 1.4968010187149048), (15278, 1.471555...\n",
       "3219   131256  [(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...\n",
       "24171  131258  [(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...\n",
       "15295  131260  [(18792, 2.265856981277466), (14672, 2.2063508...\n",
       "19746  131262  [(0, 0.0), (10, 0.0), (20, 0.0), (30, 0.0), (4...\n",
       "\n",
       "[25297 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "i = 0\n",
    "res = []\n",
    "for lines in df_rec.values:\n",
    "    userID = lines[0]\n",
    "    items = [line[0] for line in lines[1]]\n",
    "    while userID != i:\n",
    "        res.append(np.random.randint(0,131262,10).tolist())\n",
    "        i = i + 1\n",
    "    \n",
    "    res.append(items)\n",
    "    i = i +1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131263"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "fw = open('markov_similarity.pkl','wb')  \n",
    "pickle.dump(res, fw, -1)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
